{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "delayed-words",
   "metadata": {},
   "source": [
    "# Sub-Entities' tables\n",
    "This notebook will create the `.csv` files for the tables:\n",
    "* Location\n",
    "* Road\n",
    "* Pcf\n",
    "* Vehicule\n",
    "\n",
    "None of these require any other table to be created, they should then be the first to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "respiratory-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "oriented-tournament",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collision = pd.read_csv(\"../collisions_clean.csv\", dtype={\"officer_id\":str, \"case_id\":str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "assisted-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id                      object\n",
      "collision_date               object\n",
      "collision_severity            int64\n",
      "collision_time               object\n",
      "county_city_location          int64\n",
      "hit_and_run                  object\n",
      "jurisdiction                float64\n",
      "lighting                     object\n",
      "location_type                object\n",
      "officer_id                   object\n",
      "pcf_violation               float64\n",
      "pcf_violation_category      float64\n",
      "pcf_violation_subsection     object\n",
      "population                  float64\n",
      "primary_collision_factor     object\n",
      "process_date                 object\n",
      "ramp_intersection           float64\n",
      "road_condition_1             object\n",
      "road_condition_2             object\n",
      "road_surface                 object\n",
      "tow_away                    float64\n",
      "type_of_collision            object\n",
      "weather_1                    object\n",
      "weather_2                    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(collision.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "painful-consolidation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "party = pd.read_csv(\"../parties_clean.csv\", dtype={\"hazardous_materials\":str, \"party_safety_equipment_2\":str, \"school_bus_related\":str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "final-assurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at_fault                          int64\n",
      "case_id                           int64\n",
      "cellphone_use                    object\n",
      "financial_responsibility         object\n",
      "hazardous_materials              object\n",
      "id                                int64\n",
      "movement_preceding_collision     object\n",
      "other_associated_factor_1        object\n",
      "other_associated_factor_2        object\n",
      "party_age                       float64\n",
      "party_drug_physical              object\n",
      "party_number                      int64\n",
      "party_safety_equipment_1         object\n",
      "party_safety_equipment_2         object\n",
      "party_sex                        object\n",
      "party_sobriety                   object\n",
      "party_type                      float64\n",
      "school_bus_related               object\n",
      "statewide_vehicle_type           object\n",
      "vehicle_make                     object\n",
      "vehicle_year                    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(party.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "romance-litigation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "victim = pd.read_csv(\"../victims_clean.csv\", dtype={\"party_safety_equipment_2\":str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "animated-andorra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id                        int64\n",
      "id                             int64\n",
      "party_number                   int64\n",
      "victim_age                   float64\n",
      "victim_degree_of_injury      float64\n",
      "victim_ejected               float64\n",
      "victim_role                    int64\n",
      "victim_safety_equipment_1     object\n",
      "victim_safety_equipment_2     object\n",
      "victim_seating_position      float64\n",
      "victim_sex                    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(victim.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-cotton",
   "metadata": {},
   "source": [
    "## Location\n",
    "\n",
    "We have to read `county_city_location` and `population` entries from `collision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "oriented-highlight",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_location = pd.DataFrame()\n",
    "df_location['county_city_location'] = collision['county_city_location']\n",
    "df_location['population'] = collision['population']\n",
    "df_location['population'] = df_location['population'].astype('Int32')\n",
    "\n",
    "df_location = df_location.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "advised-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location.to_csv(r'../location.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "established-radiation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    county_city_location  population\n",
      "0                   1900         9.0\n",
      "1                   1500         9.0\n",
      "2                   1502         6.0\n",
      "3                   3711         7.0\n",
      "4                   3318         4.0\n",
      "5                   1942         7.0\n",
      "6                   1953         6.0\n",
      "7                   1902         5.0\n",
      "8                   1925         6.0\n",
      "9                   1000         9.0\n",
      "10                  1005         7.0\n",
      "11                  3701         5.0\n",
      "12                  3019         7.0\n",
      "13                  3026         6.0\n",
      "14                  3001         7.0\n",
      "15                  5400         9.0\n",
      "16                  5405         4.0\n",
      "17                  1515         1.0\n",
      "18                   900         9.0\n",
      "19                  4313         7.0\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"../location.csv\")\n",
    "    \n",
    "print(test.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-insured",
   "metadata": {},
   "source": [
    "## Road\n",
    "We have to read `road_surface`, `lighting`, `location_type`, `ramp_intersection` entries from `collision`. We'll also generate a primary key `road_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "simplified-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_road = pd.DataFrame()\n",
    "df_road['road_surface'] = collision['road_surface']\n",
    "df_road['lighting'] = collision['lighting']\n",
    "df_road['location_type'] = collision['location_type']\n",
    "df_road['ramp_intersection'] = collision['ramp_intersection']\n",
    "\n",
    "df_road['ramp_intersection'] = df_road['ramp_intersection'].astype('Int32')\n",
    "\n",
    "df_road = df_road.drop_duplicates()\n",
    "\n",
    "df_road['road_id'] = range(0,len(df_road))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "virgin-timer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   road_surface lighting location_type  ramp_intersection  road_id\n",
      "0             A        A           NaN                NaN        0\n",
      "1             A      NaN           NaN                NaN        1\n",
      "2             A        A             H                NaN        2\n",
      "3             A        B           NaN                NaN        3\n",
      "4             A        C           NaN                NaN        4\n",
      "5             A        A             I                5.0        5\n",
      "6             A        D           NaN                NaN        6\n",
      "7             A        D             H                NaN        7\n",
      "8             B        A             H                NaN        8\n",
      "9             A        A             R                1.0        9\n",
      "10            A        A             R                2.0       10\n",
      "11            A        C             H                NaN       11\n",
      "12            A        D             R                2.0       12\n",
      "13            A        C             R                2.0       13\n",
      "14            B        A           NaN                NaN       14\n",
      "15            C        A             H                NaN       15\n",
      "16            C        A           NaN                NaN       16\n",
      "17            A        C             R                4.0       17\n",
      "18            B        D           NaN                NaN       18\n",
      "19            A        A             R                3.0       19\n"
     ]
    }
   ],
   "source": [
    "df_road.to_csv(r'../road.csv', index = False)\n",
    "\n",
    "test = pd.read_csv(\"../road.csv\")\n",
    "    \n",
    "print(test.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-marble",
   "metadata": {},
   "source": [
    "## PCF\n",
    "We have to read `pcf_violation`, `pcf_violation_category`, `pcf_violation_subsection` in `collisions`. We'll also generate a primary key `pcf_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "posted-intellectual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 561 unique 561\n"
     ]
    }
   ],
   "source": [
    "df_pcf = pd.DataFrame()\n",
    "df_pcf['pcf_violation'] = collision['pcf_violation']\n",
    "df_pcf['pcf_violation_category'] = collision['pcf_violation_category']\n",
    "df_pcf['pcf_violation_subsection'] = collision['pcf_violation_subsection']\n",
    "df_pcf['primary_collision_factor'] = collision['primary_collision_factor']\n",
    "\n",
    "df_pcf['pcf_violation_category']= df_pcf['pcf_violation_category'].astype('Int32')\n",
    "\n",
    "df_pcf = df_pcf.drop_duplicates()\n",
    "\n",
    "df_pcf['pcf_id'] = range(0,len(df_pcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "qualified-greenhouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pcf_violation  pcf_violation_category pcf_violation_subsection  \\\n",
      "0         22107.0                     8.0                      NaN   \n",
      "1         22515.0                    13.0                        A   \n",
      "2         23114.0                    17.0                        A   \n",
      "3         22450.0                    12.0                        A   \n",
      "4         22350.0                     3.0                      NaN   \n",
      "5         22106.0                    19.0                      NaN   \n",
      "6         21658.0                     7.0                        A   \n",
      "7         21801.0                     9.0                        A   \n",
      "8         21451.0                    17.0                        A   \n",
      "9         21202.0                     5.0                        A   \n",
      "10        21453.0                    12.0                        A   \n",
      "11        23152.0                     1.0                        A   \n",
      "12        21453.0                     9.0                        C   \n",
      "13            NaN                    18.0                      NaN   \n",
      "14            NaN                    24.0                      NaN   \n",
      "15        21750.0                     6.0                      NaN   \n",
      "16        21950.0                    10.0                        A   \n",
      "17        21802.0                     9.0                        A   \n",
      "18        21662.0                    17.0                        A   \n",
      "19            NaN                     0.0                      NaN   \n",
      "\n",
      "   primary_collision_factor  pcf_id  \n",
      "0                         A       0  \n",
      "1                         A       1  \n",
      "2                         A       2  \n",
      "3                         A       3  \n",
      "4                         A       4  \n",
      "5                         A       5  \n",
      "6                         A       6  \n",
      "7                         A       7  \n",
      "8                         A       8  \n",
      "9                         A       9  \n",
      "10                        A      10  \n",
      "11                        A      11  \n",
      "12                        A      12  \n",
      "13                        C      13  \n",
      "14                        E      14  \n",
      "15                        A      15  \n",
      "16                        A      16  \n",
      "17                        A      17  \n",
      "18                        A      18  \n",
      "19                        D      19  \n"
     ]
    }
   ],
   "source": [
    "df_pcf.to_csv(r'../pcf.csv', index = False)\n",
    "\n",
    "test = pd.read_csv(\"../pcf.csv\")\n",
    "    \n",
    "print(test.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-junior",
   "metadata": {},
   "source": [
    "## Vehicule\n",
    "We have to read `statewide_vehicule_type`, `vehicule_make`, `vehicule_year` in `party`. We'll also generate a primary key `vehicule_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "frequent-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vehicle = pd.DataFrame()\n",
    "df_vehicle['statewide_vehicle_type'] = party['statewide_vehicle_type']\n",
    "df_vehicle['vehicle_make'] = party['vehicle_make']\n",
    "df_vehicle['vehicle_year'] = party['vehicle_year']\n",
    "\n",
    "df_vehicle = df_vehicle.drop_duplicates()\n",
    "\n",
    "df_vehicle['vehicle_id'] = range(0,len(df_vehicle))\n",
    "\n",
    "df_vehicle['vehicle_year'] = df_vehicle['vehicle_year'].astype('Int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "random-embassy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   statewide_vehicle_type  vehicle_make  vehicle_year  vehicle_id\n",
      "0                       A          FORD        2000.0           0\n",
      "1                       A         BUICK        1992.0           1\n",
      "2                       D        TOYOTA           NaN           2\n",
      "3                       A          FORD        1995.0           3\n",
      "4                       D           NaN           NaN           4\n",
      "5                       A         HONDA           NaN           5\n",
      "6                       A        TOYOTA        2001.0           6\n",
      "7                       G  FREIGHTLINER        2001.0           7\n",
      "8                       A     CHEVROLET        1997.0           8\n",
      "9                       D          FORD        2001.0           9\n",
      "10                      A     CHEVROLET        1991.0          10\n",
      "11                      A         DODGE        1996.0          11\n",
      "12                      D         DODGE        1997.0          12\n",
      "13                      D     CHEVROLET        1994.0          13\n",
      "14                      D          FORD        1985.0          14\n",
      "15                      D        NISSAN        1985.0          15\n",
      "16                      A      CHRYSLER        1991.0          16\n",
      "17                      D    MITSUBISHI        1988.0          17\n",
      "18                      A         HONDA        1991.0          18\n",
      "19                      D         DODGE        1999.0          19\n"
     ]
    }
   ],
   "source": [
    "df_vehicle.to_csv(r'../vehicle.csv', index = False)\n",
    "\n",
    "test = pd.read_csv(\"../vehicle.csv\")\n",
    "    \n",
    "print(test.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-relay",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
