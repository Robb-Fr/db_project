{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "official-appeal",
   "metadata": {},
   "source": [
    "# Sub-Entities' tables\n",
    "This notebook will create the `.csv` files for the tables:\n",
    "* Location\n",
    "* Road\n",
    "* Pcf\n",
    "* Vehicule\n",
    "\n",
    "None of these require any other table to be created, they should then be the first to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "understood-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "rough-wright",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3155: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "collision = pd.read_csv(\"../collisions_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "familiar-deposit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3155: DtypeWarning: Columns (4,13,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "party = pd.read_csv(\"../parties_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "logical-blind",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3155: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "vicitm = pd.read_csv(\"../victims_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-establishment",
   "metadata": {},
   "source": [
    "## Location\n",
    "\n",
    "We have to read `county_city_location` and `population` entries from `collision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "wrong-taste",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_location = pd.DataFrame()\n",
    "df_location['county_city_location'] = collision['county_city_location']\n",
    "df_location['population'] = collision['population']\n",
    "\n",
    "df_location = df_location.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "hazardous-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location.to_csv(r'../location.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "better-mattress",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    county_city_location  population\n",
      "0                   1900         9.0\n",
      "1                   1500         9.0\n",
      "2                   1502         6.0\n",
      "3                   3711         7.0\n",
      "4                   3318         4.0\n",
      "5                   1942         7.0\n",
      "6                   1953         6.0\n",
      "7                   1902         5.0\n",
      "8                   1925         6.0\n",
      "9                   1000         9.0\n",
      "10                  1005         7.0\n",
      "11                  3701         5.0\n",
      "12                  3019         7.0\n",
      "13                  3026         6.0\n",
      "14                  3001         7.0\n",
      "15                  5400         9.0\n",
      "16                  5405         4.0\n",
      "17                  1515         1.0\n",
      "18                   900         9.0\n",
      "19                  4313         7.0\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"../location.csv\")\n",
    "    \n",
    "print(test.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-english",
   "metadata": {},
   "source": [
    "## Road\n",
    "We have to read `road_surface`, `lighting`, `location_type`, `ramp_intersection` entries from `collision`. We'll also generate a primary key `road_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "incident-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_road = pd.DataFrame()\n",
    "df_road['road_surface'] = collision['road_surface']\n",
    "df_road['lighting'] = collision['lighting']\n",
    "df_road['location_type'] = collision['location_type']\n",
    "df_road['ramp_intersection'] = collision['ramp_intersection']\n",
    "\n",
    "df_road.drop_duplicates()\n",
    "\n",
    "df_road['road_id'] = range(0,len(df_road))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "indoor-venture",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   road_surface lighting location_type  ramp_intersection  road_id\n",
      "0             A        A           NaN                NaN        0\n",
      "1             A      NaN           NaN                NaN        1\n",
      "2             A        A             H                NaN        2\n",
      "3             A        A           NaN                NaN        3\n",
      "4             A        A           NaN                NaN        4\n",
      "5             A        B           NaN                NaN        5\n",
      "6             A        C           NaN                NaN        6\n",
      "7             A        A             H                NaN        7\n",
      "8             A        A           NaN                NaN        8\n",
      "9             A        A           NaN                NaN        9\n",
      "10            A        A           NaN                NaN       10\n",
      "11            A        A           NaN                NaN       11\n",
      "12            A        A           NaN                NaN       12\n",
      "13            A        A           NaN                NaN       13\n",
      "14            A        A             H                NaN       14\n",
      "15            A        C           NaN                NaN       15\n",
      "16            A        C           NaN                NaN       16\n",
      "17            A        A             I                5.0       17\n",
      "18            A        A             H                NaN       18\n",
      "19            A        B           NaN                NaN       19\n"
     ]
    }
   ],
   "source": [
    "df_road.to_csv(r'../road.csv', index = False)\n",
    "\n",
    "test = pd.read_csv(\"../road.csv\")\n",
    "    \n",
    "print(test.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-panic",
   "metadata": {},
   "source": [
    "## PCF\n",
    "We have to read `pcf_violation`, `pcf_violation_category`, `pcf_violation_subsection` in `collisions`. We'll also generate a primary key `pcf_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "material-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pcf = pd.DataFrame()\n",
    "df_pcf['pcf_violation'] = collision['pcf_violation']\n",
    "df_pcf['pcf_violation_category'] = collision['pcf_violation_category']\n",
    "df_pcf['pcf_violation_subsection'] = collision['pcf_violation_subsection']\n",
    "\n",
    "df_pcf.drop_duplicates()\n",
    "\n",
    "df_pcf['pcf_id'] = range(0,len(df_pcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "failing-legend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pcf_violation  pcf_violation_category pcf_violation_subsection  pcf_id\n",
      "0         22107.0                     8.0                      NaN       0\n",
      "1         22515.0                    13.0                        A       1\n",
      "2         23114.0                    17.0                        A       2\n",
      "3         22450.0                    12.0                        A       3\n",
      "4         22350.0                     3.0                      NaN       4\n",
      "5         22106.0                    19.0                      NaN       5\n",
      "6         21658.0                     7.0                        A       6\n",
      "7         22350.0                     3.0                      NaN       7\n",
      "8         21801.0                     9.0                        A       8\n",
      "9         22106.0                    19.0                      NaN       9\n",
      "10        21451.0                    17.0                        A      10\n",
      "11        21202.0                     5.0                        A      11\n",
      "12        21453.0                    12.0                        A      12\n",
      "13        22350.0                     3.0                      NaN      13\n",
      "14        22107.0                     8.0                      NaN      14\n",
      "15        21453.0                    12.0                        A      15\n",
      "16        23152.0                     1.0                        A      16\n",
      "17        21453.0                     9.0                        C      17\n",
      "18        22107.0                     8.0                      NaN      18\n",
      "19        22107.0                     8.0                      NaN      19\n"
     ]
    }
   ],
   "source": [
    "df_pcf.to_csv(r'../pcf.csv', index = False)\n",
    "\n",
    "test = pd.read_csv(\"../pcf.csv\")\n",
    "    \n",
    "print(test.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-office",
   "metadata": {},
   "source": [
    "## Vehicule\n",
    "We have to read `statewide_vehicule_type`, `vehicule_make`, `vehicule_year` in `party`. We'll also generate a primary key `vehicule_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "reasonable-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vehicle = pd.DataFrame()\n",
    "df_vehicle['statewide_vehicle_type'] = party['statewide_vehicle_type']\n",
    "df_vehicle['vehicle_make'] = party['vehicle_make']\n",
    "df_vehicle['vehicle_year'] = party['vehicle_year']\n",
    "\n",
    "df_vehicle.drop_duplicates()\n",
    "\n",
    "df_vehicle['vehicle_id'] = range(0,len(df_vehicle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "critical-solid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   statewide_vehicle_type  vehicle_make  vehicle_year  vehicle_id\n",
      "0                       A          FORD        2000.0           0\n",
      "1                       A         BUICK        1992.0           1\n",
      "2                       D        TOYOTA           NaN           2\n",
      "3                       A          FORD        1995.0           3\n",
      "4                       D           NaN           NaN           4\n",
      "5                       A         HONDA           NaN           5\n",
      "6                       A        TOYOTA        2001.0           6\n",
      "7                       G  FREIGHTLINER        2001.0           7\n",
      "8                       A     CHEVROLET        1997.0           8\n",
      "9                       D          FORD        2001.0           9\n",
      "10                      A     CHEVROLET        1991.0          10\n",
      "11                      A         DODGE        1996.0          11\n",
      "12                      D         DODGE        1997.0          12\n",
      "13                      D     CHEVROLET        1994.0          13\n",
      "14                      D          FORD        1985.0          14\n",
      "15                      D        NISSAN        1985.0          15\n",
      "16                      A      CHRYSLER        1991.0          16\n",
      "17                      D    MITSUBISHI        1988.0          17\n",
      "18                      A         HONDA        1991.0          18\n",
      "19                      D         DODGE        1999.0          19\n"
     ]
    }
   ],
   "source": [
    "df_vehicle.to_csv(r'../vehicle.csv', index = False)\n",
    "\n",
    "test = pd.read_csv(\"../vehicle.csv\")\n",
    "    \n",
    "print(test.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-personality",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
